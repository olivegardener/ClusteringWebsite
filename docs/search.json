[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "On this about page, you might want to add more information about yourself, the project, or course. Any helpful context could go here!\nMy name is Nick Hand, the instructor for the course. You can find more information about me on my personal website.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2023.\nAdipisicing proident minim non non dolor quis. Pariatur in ipsum aliquip magna. Qui ad aliqua nulla excepteur dolor nostrud quis nisi. Occaecat proident eiusmod in cupidatat. Elit qui laboris sit aliquip proident dolore. Officia commodo commodo in eiusmod aliqua sint cupidatat consectetur aliqua sint reprehenderit.\nOccaecat incididunt esse et elit adipisicing sit est cupidatat consequat. Incididunt exercitation amet dolor non sit anim veniam veniam sint velit. Labore irure reprehenderit ut esse. Minim quis commodo nisi voluptate."
  },
  {
    "objectID": "analysis/HotspotClustering.html",
    "href": "analysis/HotspotClustering.html",
    "title": "Hotspot Clustering",
    "section": "",
    "text": "This Jupyter Notebooks script performs k means clustering and data visualization on three data outputs from WeightedOverlayRasters, using them to make high-level planning recommendations for urban development and conservation prioritization.\nHere are descriptions of the three datasets used in this analysis:\n\nBio_x_Risk emphasizes areas of high land cover change probability and high biodiversity intactness.\n\nBio_x_Risk = LCC_Probability x BII \n\nAnthro_x_Risk emphasizes areas of high climate hazard probability and high human population.\n\nAnthro_x_Risk = Climate_Hazards x pop2020 \n\nUrban Land Cover Probability is a dataset generated using a random forest model trained on a range of physiographic factors to predict the likelihood of a raster cell to be urban in 2033."
  },
  {
    "objectID": "analysis/HotspotClustering.html#introduction",
    "href": "analysis/HotspotClustering.html#introduction",
    "title": "Hotspot Clustering",
    "section": "",
    "text": "This Jupyter Notebooks script performs k means clustering and data visualization on three data outputs from WeightedOverlayRasters, using them to make high-level planning recommendations for urban development and conservation prioritization.\nHere are descriptions of the three datasets used in this analysis:\n\nBio_x_Risk emphasizes areas of high land cover change probability and high biodiversity intactness.\n\nBio_x_Risk = LCC_Probability x BII \n\nAnthro_x_Risk emphasizes areas of high climate hazard probability and high human population.\n\nAnthro_x_Risk = Climate_Hazards x pop2020 \n\nUrban Land Cover Probability is a dataset generated using a random forest model trained on a range of physiographic factors to predict the likelihood of a raster cell to be urban in 2033."
  },
  {
    "objectID": "analysis/HotspotClustering.html#data-formatting",
    "href": "analysis/HotspotClustering.html#data-formatting",
    "title": "Hotspot Clustering",
    "section": "Data Formatting",
    "text": "Data Formatting\nLoad raster datasets and remove any NoData values that might be present\n\n\nCode\n# Load the raster datasets\nAnthroRisk_path = '/Users/oliveratwood/Documents/GitHub/HotspotStoplight/clustering/data/AnthroRiskNorm.tif'\nBioRisk_path = '/Users/oliveratwood/Documents/GitHub/HotspotStoplight/clustering/data/BioRiskNorm.tif'\nUrbanProbability_path = '/Users/oliveratwood/Documents/GitHub/HotspotStoplight/clustering/data/UrbanProbability.tif'\n\n\nwith rasterio.open(AnthroRisk_path) as AnthroRisk_dataset:\n    AnthroRisk = AnthroRisk_dataset.read(1)\n\ntransform = AnthroRisk_dataset.transform\n\n# Function to read raster and replace NoData values\ndef read_raster_and_replace_nodata(path):\n    with rasterio.open(path) as dataset:\n        # Read the first band\n        data = dataset.read(1)\n        # Get the NoData value\n        nodata_value = dataset.nodatavals[0]\n        if nodata_value is not None:\n            # Replace NoData values with NaN\n            data = np.where(data == nodata_value, np.nan, data)\n    return data\n\n# Load the raster datasets and remove NoData values\nAnthroRisk = read_raster_and_replace_nodata(AnthroRisk_path)\nBioRisk = read_raster_and_replace_nodata(BioRisk_path)\nUrbanProbability = read_raster_and_replace_nodata(UrbanProbability_path)\n\n\nPlot datasets to be clustered\n\n\nCode\n# List of tuples containing raster datasets and their titles\nraster_data = [\n    (AnthroRisk, 'Anthropogenic Risk'),\n    (BioRisk, 'Biodiversity Risk'),\n    (UrbanProbability, 'Urban Probability'),\n]\n\n# Set a dark background style\nplt.style.use('dark_background')\n\n# Create a figure with 3 subplots (arranged vertically)\nfig, axs = plt.subplots(3, 1, figsize=(40, 25))  # Adjust the figure size as needed\n\n# Loop through each raster dataset and plot in subplots\nfor i, (data, title) in enumerate(raster_data):\n    im = axs[i].imshow(data, cmap=cc.cm.bmy)  # Use a specified colormap\n    axs[i].set_title(title, color='white', fontsize=30, pad=30)  # Increase the title font size and padding\n\n    # Remove the labels on the axes\n    axs[i].set_xticks([])\n    axs[i].set_yticks([])\n\n    # Create an axis for the colorbar\n    divider = make_axes_locatable(axs[i])\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.5)\n\n    # Add colorbar to the created axis\n    fig.colorbar(im, cax=cax, orientation='vertical')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n\n\n\n\n\nMerge the rasters into a single dataframe for clustering\n\n\nCode\n# Ensure all rasters have the same shape\nassert AnthroRisk.shape == BioRisk.shape == UrbanProbability.shape, \"Rasters must be of the same size\"\n\n# Get coordinates\nrows, cols = np.indices(AnthroRisk.shape)\nxs, ys = rasterio.transform.xy(transform, rows, cols)\n\n# Dictionary of arrays\narrays = {\n    'x': np.array(xs),\n    'y': np.array(ys),\n    'Anthropogenic_Risk': AnthroRisk,\n    'Biodiversity_Risk': BioRisk,\n    'Urban_Probability': UrbanProbability\n}\n\n\n# Flatten the arrays\nflattened_arrays = {key: value.flatten() for key, value in arrays.items()}\n\n# Create a DataFrame\ndf = pd.DataFrame(flattened_arrays)\n\n# Drop NaN values if necessary\ndf.dropna(inplace=True)\n\n# df.head()\n\n\nStandardize the data columns for clustering\n\n\nCode\n# Standardization\nstandard_scaler = StandardScaler()\nX = standard_scaler.fit_transform(df[['Anthropogenic_Risk', 'Biodiversity_Risk', 'Urban_Probability']])"
  },
  {
    "objectID": "analysis/HotspotClustering.html#k-means-clustering",
    "href": "analysis/HotspotClustering.html#k-means-clustering",
    "title": "Hotspot Clustering",
    "section": "K-Means Clustering",
    "text": "K-Means Clustering\nPerform K-means clustering\n\n\nCode\n# Number of clusters to try out\nn_clusters = list(range(2, 15))\n\n# Run kmeans for each value of k\ninertias = []\nfor k in n_clusters:\n    \n    # Initialize and run\n    kmeans = KMeans(n_clusters=k, n_init=10, max_iter=600)\n    kmeans.fit(X)\n    \n    # Save the \"inertia\"\n    inertias.append(kmeans.inertia_)\n    \n# Plot it!\n# Set a dark background style for the plot\nplt.style.use('dark_background')\n\n# Plotting the data\nplt.plot(n_clusters, inertias, marker='o', ms=10, mfc='white', lw=4, mew=3, color='blue')\n\n# Setting labels and title with light color for visibility\nplt.title('Inertia vs Number of Clusters', color='white')\nplt.xlabel('Number of Clusters', color='white')\nplt.ylabel('Inertia', color='white')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nDetermine the appropriate number of clusters using KneeLocator\n\n\nCode\n# Initialize the knee algorithm\nkn = KneeLocator(n_clusters, inertias, curve='convex', direction='decreasing')\n\n# Print out the knee \nprint(kn.knee)\n\n\n4\n\n\nFit the appropriate number of clusters to the data\n\n\nCode\n# Initialize the Kmeans object\n# Using the identified knee\nkmeans = KMeans(n_clusters=(kn.knee), random_state=42, n_init=10)\n\n# Using a manually-assigned knee\n# kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n\n# Run the fit! This adds the \".labels_\" attribute\nkmeans.fit(X);\n\n# Save the cluster labels\ndf[\"cluster\"] = kmeans.labels_\n\ndf.head()\n\n\n\n\n\n\n\n\n\nx\ny\nAnthropogenic_Risk\nBiodiversity_Risk\nUrban_Probability\ncluster\n\n\n\n\n0\n-84.389663\n10.129249\n0.0\n0.668739\n0.000073\n0\n\n\n1\n-84.389385\n10.129249\n0.0\n0.665026\n0.000071\n0\n\n\n2\n-84.389107\n10.129249\n0.0\n0.661313\n0.000083\n0\n\n\n3\n-84.388829\n10.129249\n0.0\n0.655744\n0.000098\n0\n\n\n4\n-84.388552\n10.129249\n0.0\n0.653149\n0.000103\n0\n\n\n\n\n\n\n\n\n\nCode\n# Count the number of rows for each cluster and sort them to see which clusters have the greatest number of rows\ncluster_counts = df['cluster'].value_counts().sort_values(ascending=False)\n\n# Display the counts\nprint('Number of Pixels per Cluster')\nprint(cluster_counts)\n# print(df.dtypes)\n\n\nNumber of Pixels per Cluster\n1    971354\n0    924702\n2    228555\n3    112740\nName: cluster, dtype: int64\n\n\nMake a multi-bar chart for each cluster\n\n\nCode\n# Group by 'cluster' and calculate mean for each column\ncluster_summary = df.groupby('cluster')[['Anthropogenic_Risk', 'Biodiversity_Risk', 'Urban_Probability']].mean()\n\n# Normalize the data\ncluster_summary_normalized = (cluster_summary - cluster_summary.min()) / (cluster_summary.max() - cluster_summary.min())\n\n# Set dark mode style\nplt.style.use('dark_background')\n\n# Define the number of groups and bar width\nn_groups = len(cluster_summary_normalized)\nbar_width = 0.25\n\n# Define x coordinates for each group\nindex = np.arange(n_groups)\nx1 = index - bar_width\nx2 = index\nx3 = index + bar_width\n\n# Plotting each column in grouped bars\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Titles and colors for each plot\ncolumns = ['Anthropogenic_Risk', 'Biodiversity_Risk', 'Urban_Probability']\ncolors = ['#3e208d', '#a02300', 'darkgrey']\nplot_titles = ['Anthropogenic Risk Per Cluster', 'Biodiversity Risk per Cluster', 'Urban Probability per Cluster']\n\n# Use a for loop to create each group of bars\nfor x, color, column, title in zip([x1, x2, x3], colors, columns, plot_titles):\n    ax.bar(x, cluster_summary_normalized[column], bar_width, label=title, color=color)\n\n# Add titles, labels, and legend\nax.set_title('Normalized Average Values per Cluster', color='white')\nax.set_xlabel('Cluster', color='white')\nax.set_ylabel('Normalized Average Values', color='white')\nax.legend()\n\n# Set x-ticks to be in the middle of the group of bars\nax.set_xticks(index)\nax.set_xticklabels(cluster_summary.index)\n\n# Adjust layout and show plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nHere we see how each one of the clusters is composed of a different combination of values of each index we’re clustering on. Let’s put together some high-level takeaways about the implications of each of these."
  },
  {
    "objectID": "analysis/HotspotClustering.html#findings",
    "href": "analysis/HotspotClustering.html#findings",
    "title": "Hotspot Clustering",
    "section": "Findings",
    "text": "Findings\n\nLand in Cluster 0 should be considered for conservation, as this means they have a high combination of land cover change probability and biodiversity.\n\nNo Anthropogenic Risk, High Biodiversity Risk, No Probability of Urban Land Cover  \n\nLand in Cluster 1 can be thought of as regional landscape assets. Their low risk level makes conservation a lower prioirty, but minimizing human impact on these lands will help maintain regional biodiversity.\n\nNo Anthropogenic Risk, Low Biodiversity Risk, No Probability of Urban Land Cover  \n\nLand in Cluster 2 is the most suitable for urban development out of the four clusters, since anthropogenic risk and biodiversity risk are relatively low there.\n\nLow Anthropogenic Risk, Low Biodiversity Risk, High Probability of Urban Land Cover  \n\nLand in Cluster 3 should be considered for Nature-Based Solutions (NbS) implementation, such as green stormwater infrastructure, either in the form of retrofits or included in areas of new urban development.\n\nHigh Anthropogenic Risk, No Biodiversity Risk, High Probability of Urban Land Cover"
  },
  {
    "objectID": "analysis/HotspotClustering.html#visualizations",
    "href": "analysis/HotspotClustering.html#visualizations",
    "title": "Hotspot Clustering",
    "section": "Visualizations",
    "text": "Visualizations\nPlot the clusters across space\n\n\nCode\n# Set the style of the visualization with a dark background\nsns.set(style=\"darkgrid\")\n\ncustom_palette = {\n    0: '#cd0000',\n    1: '#328232',\n    2: '#A9A9A9',\n    3: '#277bdb',\n}\n\n# Create a scatter plot with the custom palette\nplt.figure(figsize=(10, 6))\nscatter = sns.scatterplot(\n    x='x', \n    y='y', \n    hue='cluster', \n    palette=custom_palette, \n    data=df, \n    s=0.5  # Point size\n)\n\n# Adding title and labels with a light color for visibility against the dark background\nplt.title('K Means Clustering', color='white')\nplt.xlabel('X Coordinate', color='white')\nplt.ylabel('Y Coordinate', color='white')\n\n# Change the color of ticks and labels for visibility\nplt.xticks(color='white')\nplt.yticks(color='white')\n\n# Modify legend for better visibility on dark background\nlegend = plt.legend(title='Cluster', loc='upper right', bbox_to_anchor=(1.1, 1.05), frameon=True)\nplt.setp(legend.get_texts(), color='white')  # Set the legend text color\nplt.setp(legend.get_title(), color='white')  # Set the legend title color\n\n# Set the face and edge color of the figure to match the dark theme\nplt.gcf().set_facecolor('#303030')\nplt.gca().set_facecolor('#303030')\nplt.gca().spines['top'].set_color('white')\nplt.gca().spines['bottom']. set_color('white')\nplt.gca().spines['left'].set_color('white')\nplt.gca().spines['right'].set_color('white')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nThis plot shows us how there are two types of clusters in the urban area and two types of clustes in the non-urban area.\n\n\nCode\n# Sample the DataFrame at 5%\nsampled_df = df.sample(frac=0.05)\n\n# Create a 3D scatter plot using Plotly\nfig = px.scatter_3d(\n    sampled_df,\n    x='Anthropogenic_Risk',\n    y='Biodiversity_Risk',\n    z='Urban_Probability',\n    title='3D Scatter Plot',\n    labels={\n        'Anthropogenic_Risk': 'Anthropogenic Risk Index',\n        'Biodiversity_Risk': 'Biodiversity Risk Index',\n        'Urban_Probability': 'Suitability of Urban Land Cover',\n        'cluster': 'Cluster'\n    }\n)\n\n# Update marker colors and hover information directly\nfig.update_traces(\n    marker=dict(\n        size=1.5,\n        color=[custom_palette[c] for c in sampled_df['cluster']],\n        opacity=0.75\n    ),\n    hovertemplate=\"Anthropogenic Risk: %{x}&lt;br&gt;Biodiversity Risk: %{y}&lt;br&gt;Urban Probability: %{z}&lt;br&gt;Cluster: %{customdata}\"\n)\n\n# Add custom data for hover information\nfig.update_traces(customdata=sampled_df['cluster'])\n\n\n# Update the layout for dark mode\nfig.update_layout(\n    margin=dict(l=0, r=0, b=0, t=0),\n    paper_bgcolor='rgb(10,10,10)',\n    plot_bgcolor='rgb(10,10,10)',\n    title_font_color='white',\n    font_color='white',\n    height=900,\n    width=1600,\n    scene=dict(\n        xaxis=dict(\n            backgroundcolor='rgb(32,32,32)',\n            gridcolor='gray',\n            showbackground=True,\n            zerolinecolor='gray'),\n        yaxis=dict(\n            backgroundcolor='rgb(32,32,32)',\n            gridcolor='gray',\n            showbackground=True,\n            zerolinecolor='gray'),\n        zaxis=dict(\n            backgroundcolor='rgb(32,32,32)',\n            gridcolor='gray',\n            showbackground=True,\n            zerolinecolor='gray'),\n    )\n)\n\n# Show the plot\nfig.show()\n\n\n\n                                                \n\n\nThis interactive plot allows us to visualize each of the factors as it varies within the cluster. Try zooming in and rotating!"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html",
    "href": "analysis/WeightedOverlayRasters.html",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "This r markdown script pre-processes raster data used in the Hotspot Stoplight Project for visualization and cluster analysis. The datasets used in this project are as follows:\n\nLAND COVER CHANGE PROBABILITY - Clark Labs\nBIODIVERSITY INTACTNESS INDEX - Impact Observatory\nCLIMATE RISK INDEX - Hotspot Stoplight Team: Nissim Lebovits\nGRIDDED 2020 POPULATION - Global Human Settlements Layer\nURBAN LAND COVER PROBABILITY - Hotspot Stoplight Team: Oliver Atwood, using classified data from Tristan Grupp  \nEach of these raster datasets are loaded into R and their Coordinate Systems, Resolution, and Extent are standardized. NA values are then removed and each dataset is standardized. \nFour of these standardized datasets are then combined to produce two ‘Interaction Rasters’, using the following formulas:  Bio_x_Risk = LCC_Probability * BII  Bio_x_Risk emphasizes areas of high land cover change probability and high biodiversity intactness.  Anthro_x_Risk = Climate_Hazards * pop2020  Anthro_x_Risk emphasizes areas of high climate hazard probability and high human population.  Urban Land Cover Probability is a dataset generated through a random forest model trained on a range of physiographic factors to predict the likelihood of a given cell of a land cover raster to be urban in 2033. \nBio_x_Risk and Anthro_x_Risk were both normalized and Bio_x_Risk, Anthro_x_Risk, and Urban Land Cover Probability were exported for clustering analysis. \nThese three datasets were then added together and the resultant raster dataset was normalized to produce a ‘Stoplight for Urban Development’.\n\n\n\n\n\n\n\n\n\n\n## Coordinate system does not match\n## Resolution does not match\n## Extent does not match\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Coordinate system matches\n## Resolution matches\n## Extent matches\n\n\n\n\n\n\n\n\n## Min value: 0 Max value: 1000 \n## Min value: 0 Max value: 0.9647594 \n## Min value: 0.001399566 Max value: 0.9714958 \n## Min value: 0 Max value: 579.4982 \n## Min value: -1.582723e-14 Max value: 1\n\n\n\n\n\n## Min value: 0 Max value: 0.9497479\n## Min value: 0 Max value: 0.842676\n## Min value: 0 Max value: 1\n\n\n\n\n\n## Min value: -0.9994601 Max value: 0.9963884"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#check-raster-coordinate-systems-resolutions-and-extents",
    "href": "analysis/WeightedOverlayRasters.html#check-raster-coordinate-systems-resolutions-and-extents",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "## Coordinate system does not match\n## Resolution does not match\n## Extent does not match"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#double-check-raster-coordinate-systems-resolutions-and-extents",
    "href": "analysis/WeightedOverlayRasters.html#double-check-raster-coordinate-systems-resolutions-and-extents",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "## Coordinate system matches\n## Resolution matches\n## Extent matches"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#normalize-all-rasters",
    "href": "analysis/WeightedOverlayRasters.html#normalize-all-rasters",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "## Min value: 0 Max value: 1000 \n## Min value: 0 Max value: 0.9647594 \n## Min value: 0.001399566 Max value: 0.9714958 \n## Min value: 0 Max value: 579.4982 \n## Min value: -1.582723e-14 Max value: 1"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#generate-interaction-rasters",
    "href": "analysis/WeightedOverlayRasters.html#generate-interaction-rasters",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "## Min value: 0 Max value: 0.9497479\n## Min value: 0 Max value: 0.842676\n## Min value: 0 Max value: 1"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#overlay-rasters-to-produce-stoplight-for-urban-development",
    "href": "analysis/WeightedOverlayRasters.html#overlay-rasters-to-produce-stoplight-for-urban-development",
    "title": "Raster Pre-Processing",
    "section": "",
    "text": "## Min value: -0.9994601 Max value: 0.9963884"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#hotspot-stoplight-raster",
    "href": "analysis/WeightedOverlayRasters.html#hotspot-stoplight-raster",
    "title": "Raster Pre-Processing",
    "section": "Hotspot Stoplight Raster",
    "text": "Hotspot Stoplight Raster"
  },
  {
    "objectID": "analysis/WeightedOverlayRasters.html#export-datasets-for-further-analysis",
    "href": "analysis/WeightedOverlayRasters.html#export-datasets-for-further-analysis",
    "title": "Raster Pre-Processing",
    "section": "Export Datasets for Further Analysis",
    "text": "Export Datasets for Further Analysis"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes technical analysis done using Jupyter notebooks and R markdown. Each sub-section highlights a different script, which performs data analysis and visualization for the project’s case study location, San Jose, Costa Rica.\n\nThe R markdown script, WeightedOverlayRasters, pre-processes raster data used in the Hotspot Stoplight Project for visualization and cluster analysis.\nThe Jupyter Notebooks script, HotspotClustering, performs k means clustering and data visualization on three data outputs from WeightedOverlayRasters, using them to make high-level planning recommendations for urban development and conservation prioritization."
  },
  {
    "objectID": "index.html#about-the-project",
    "href": "index.html#about-the-project",
    "title": "Hotspot Stoplight - Clustering Analysis",
    "section": "About the Project",
    "text": "About the Project\nThe Hotspot Stoplight Project is a partnership between UN Habitat and The McHarg Center for Urbanism and Ecology at the University of Pennsylvania. The Project seeks to develop a methodology for the integration of regionally-specific climate risk, biodiversity loss, and land cover change projections into a cartographic product and a high-resolution urban suitability index we call the ‘Stoplight for Urban Development.’  This website attempts to gather together some of the preliminary findings of this research, focusing on the case study city of San Jose, Costa Rica.   The ultimate goal of this project is to use these projections to inform urban design and planning processes, bringing together data science and design to support the goals of de-siloing knowledge, projecting urban expansion to better understand where habitat loss is likely to occur, reduce habitat degradation and destruction, increase the accuracy of ecosystem services accounting, and promote deeper understanding among urban and regional planners of the interconnectedness of the natural and built environments.  ## Find out more\nThe code base for this project is located on our GitHub page:  https://github.com/HotspotStoplight/HotspotStoplight.\nA white paper published by UN Habitat, based in part on the early findings of this project can be found here:  https://unhabitat.org/cities-and-nature-planning-for-the-future"
  }
]